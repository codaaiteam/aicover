{
  "home": "Home",
  "guide": "Guide",
  "title": "Mochi 1 Preview: Open Source Video Generation with High-Fidelity Motion",
  "description": "Experience state-of-the-art video generation with exceptional motion quality and prompt adherence, powered by our 10B parameter AsymmDiT architecture",
  "tryNow": "Try on Playground",
  "seeInAction": "Featured Examples",
  "videoDescription": "Explore groundbreaking open-source video generation powered by our novel Asymmetric Diffusion Transformer",
  "unleashCreativity": "State-of-the-Art Video Generation",
  
  "feature1Title": "High-Fidelity Motion",
  "feature1Description": "Industry-leading motion quality through our 10B parameter diffusion model with strong prompt adherence in preliminary evaluation",
  
  "feature2Title": "Open Source Architecture",
  "feature2Description": "Built on the novel Asymmetric Diffusion Transformer (AsymmDiT) architecture, freely available under Apache 2.0 license",
  
  "feature3Title": "Advanced Compression",
  "feature3Description": "Featuring our open-source VAE that causally compresses videos to 128x smaller size with 8x8 spatial and 6x temporal compression",
  
  "feature4Title": "Efficient Processing",
  "feature4Description": "Streamlined text processing with single T5-XXL language model and optimized visual reasoning capacity",
  
  "feature5Title": "Multimodal Architecture",
  "feature5Description": "Joint attention to text and visual tokens with dedicated MLP layers for each modality and non-square QKV projection",
  
  "feature6Title": "Developer-Friendly",
  "feature6Description": "Simple, hackable architecture with comprehensive documentation and community support",
  
  "howToUse": "Generate Videos with Mochi 1",
  "step1Title": "Setup Environment",
  "step1Description": "Clone the repository and install dependencies using uv package manager",
  
  "step2Title": "Configure Parameters",
  "step2Description": "Set model directory, CFG scale, and seed values for controlled generation",
  
  "step3Title": "Generate Content",
  "step3Description": "Run inference through Gradio UI or command line interface",
  
  "userReviews": "Community Feedback",
  "review1": "The motion quality and prompt adherence set new standards for open-source video generation.",
  "review2": "The simple, hackable architecture makes it perfect for research and experimentation.",
  "review3": "Impressive results with the efficient single T5-XXL language model approach.",
  
  "faq": "Frequently Asked Questions",
  "faq1Question": "What makes Mochi 1 unique?",
  "faq1Answer": "Mochi 1 represents a significant advancement in open-source video generation, featuring a 10B parameter diffusion model with novel AsymmDiT architecture, offering high-fidelity motion and strong prompt adherence while being completely open source.",
  
  "faq2Question": "What are the technical specifications?",
  "faq2Answer": "Mochi 1 generates 480p videos using a 10B parameter model with 8x8 spatial and 6x temporal compression. The model requires 4 H100 GPUs for inference and uses a single T5-XXL for prompt encoding.",
  
  "faq3Question": "How does the architecture work?",
  "faq3Answer": "The AsymmDiT architecture efficiently processes prompts alongside compressed video tokens, using multi-modal self-attention with separate MLP layers for each modality and non-square QKV projections for reduced memory requirements.",
  
  "faq4Question": "What are the current limitations?",
  "faq4Answer": "The current research preview is limited to 480p resolution, may show minor warping in extreme motion cases, and is optimized for photorealistic rather than animated content.",
  
  "ctaTitle": "Join the Open Source Video Generation Revolution",
  "ctaDescription": "Experience the largest openly released video generative model",
  "ctaButton": "Try Mochi 1",
  
  "moreVideos": "More Videos"
}